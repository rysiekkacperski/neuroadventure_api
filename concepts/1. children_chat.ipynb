{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd27d38a",
   "metadata": {},
   "source": [
    "# NeuroAdventure concepts - Chatbot for children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef4815",
   "metadata": {},
   "source": [
    "Chatbot for children is a main component of the entire NeuroAdventure app and provides other components with information on child and conversation states. Chatbot is powered by LangGraph package (see more: [LangGraph website](https://langchain-ai.github.io/langgraph/)). LangGraph not only allows us to write prompts programatically directly to the api but also to create graphs which are agentic workflows performing LLM operations divided on steps.\n",
    "\n",
    "\n",
    "Key features of the chatbot are:\n",
    "- Assessment of probability if previous messages concern a social scenario experienced by a child;\n",
    "- Evaluation of probability if previous messages describe emotions felt\\being felt by a child;\n",
    "- Sentimet analysis of messages which estimate current mood of a child;\n",
    "- Response generator - creates a LLM model response based on information given e.g. age, language, mood and other factors;   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101b506",
   "metadata": {},
   "source": [
    "### LLM initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e80168",
   "metadata": {},
   "source": [
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14460c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47847ad",
   "metadata": {},
   "source": [
    "### Env variables initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98af634c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79e8d475-e590-4d26-8c8a-113bb0096e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.getenv(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd1ce53",
   "metadata": {},
   "source": [
    "Set neccessary api keys and other environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4d1f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4a4dd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00557c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"neuroadventure\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1e4d0",
   "metadata": {},
   "source": [
    "Init the LLM  model to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae21c10",
   "metadata": {},
   "source": [
    "### LangGraph state declaration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce56550",
   "metadata": {},
   "source": [
    "State is a main part of the graph which gathers and stores all infomation neccessary for LLM agent to work with and generate a satisfying, engaging and desired output. For the children chatbot, we need to store below values:\n",
    "1. messages - history of all messages exchanged between the LLM model and a child, including first system message ([More on system messages](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html));\n",
    "2. name - LLM model uses a child name to sound more natural and persuasive;\n",
    "3. age - LLM model takes into account an age of a child to create a well-tailored content e.g. older children might prefer more serious responses;\n",
    "4. adhd - a boolean indicating if a child suffers from adhd disorder;\n",
    "5. spectrum  - a boolean indicating if a child is on autism spectrum;\n",
    "6. langauge - ISO code which specifes language of the responses;\n",
    "7. mood - estimated mood experienced by a child during the conversation;\n",
    "8. summary - summary of messages;\n",
    "9. isSocialContext - boolean which determines if a social scenario expierenced by a child is presented in the chat history;\n",
    "10. isEmotionalContext - boolean which determines if previous messages were describing emotions of a child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pydantic to validate data passed to the state\n",
    "from pydantic import BaseModel, field_validator, Field\n",
    "\n",
    "# import enum to create enumarated type for pydantic BaseModel if we want the field to accept a value only from closed set of values\n",
    "from enum import Enum\n",
    "\n",
    "# langgraph use Annotated to let us declare a reducer function which update a given state key\n",
    "from typing import Annotated, Any\n",
    "\n",
    "# import to show a graphical representation of the graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#import langgraph modules\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from helpers.validation import Diagnosis\n",
    "\n",
    "#create an interface for mood \n",
    "class MoodEnum(str, Enum):\n",
    "  HAPPY = \"happy\"\n",
    "  SAD = \"sad\"\n",
    "  NEUTRAL = \"neutral\"\n",
    "  NERVOUS = \"nervous\"\n",
    "  IRRITATED = \"irritated\"\n",
    "  CURIOUS = \"curious\"\n",
    "\n",
    "def childChatBotSystemMessage(diagnosis: Diagnosis, age: int, mood: str, language: str):\n",
    "    return (f'''Pretend to be a terapist who talks with a kid in {repr(diagnosis)}. Kid is {age} years old. Their mood is {mood}. The ISO 639 code of the language you speak is {language}.\n",
    "    Remember that neurodivergent kids have special language needs. You should be very detailed but concise in the same time.''')\n",
    "\n",
    "class ChildState(BaseModel):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    name: str\n",
    "    age: int \n",
    "    diagnosis: Diagnosis\n",
    "    language: str\n",
    "    mood: MoodEnum = MoodEnum.NEUTRAL\n",
    "    isSocialContext: bool = False\n",
    "    isEmotionalContext: bool = False\n",
    "\n",
    "    @field_validator('age')\n",
    "    @classmethod\n",
    "    def validate_age(cls, value):\n",
    "        # Ensure the person is a child\n",
    "        if value >= 18:\n",
    "            raise ValueError(\"The person is not a child\")\n",
    "        return value\n",
    "\n",
    "    @field_validator('language')\n",
    "    @classmethod\n",
    "    def validate_language(cls, value):\n",
    "        # Ensure the language code is proper according to ISO standards\n",
    "        if len(value) != 2:\n",
    "            raise ValueError(\"Given language is not valid language code\")\n",
    "        return value\n",
    "\n",
    "    def model_post_init(self, __context: Any) -> None:\n",
    "        if not self.messages:\n",
    "            self.messages = [SystemMessage(content=childChatBotSystemMessage(self.diagnosis, self.age, self.mood, self.language))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881f2d6d",
   "metadata": {},
   "source": [
    "### Assessing social context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb26d52",
   "metadata": {},
   "source": [
    "Children using chatbot will often pass messages which have a social scenerio context in place (e.g. situations in school, playing with other kids etc.). The LLM model should be able to assess if any social context can be indeed identified in the messages. That will help the further nodes to properly text back the child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ed12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a formatter to store probability of social context occurence within LLM message in a given format (float)\n",
    "class SocialFormatter(BaseModel):\n",
    "  social_p: float = Field(description='Probability of social context occurence')\n",
    "\n",
    "#node for the graph\n",
    "def assess_social_context(state: ChildState):\n",
    "  social_context_prompt = \"\"\"You are a therapist of neurodivergent children. Neurodivergent kid is talking with you. Assess the probability [social_p], from 0 to 1, \n",
    "  that content of previous messages concerns social scenario experienced by a child. Remember that you should assess only HumanMessages, the ones written by a child.\"\"\"\n",
    "  \n",
    "  llm_with_structured_output = llm.with_structured_output(SocialFormatter)\n",
    "  messages = add_messages(state.messages, HumanMessage(content=social_context_prompt))\n",
    "\n",
    "  probability = llm_with_structured_output.invoke(messages)\n",
    "\n",
    "  if probability.social_p >= 0.75:\n",
    "    return {'isSocialContext': True}\n",
    "  else:\n",
    "    return {'isSocialContext': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc1a33",
   "metadata": {},
   "source": [
    "### Assessing emotional context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9b885",
   "metadata": {},
   "source": [
    "It is hard for children in autism spectrum to correctly get their emotions across. The LLM model should also assess if a content of messages involves any emotions. An example is a situation when a child write a prompt about a situation in school which could involve happiness e.g. getting a very good grade. However, those emotions will not be directly expressed. LLM model tries to identify those emotions via content of messages. For example, a scientific question will be assesed as not emotionally affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13628408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a formatter to store probability of emotional context occurence within LLM message in a given format (float)\n",
    "class EmotionFormatter(BaseModel):\n",
    "  emotion_p: float = Field(description='Probability of emotion occurence')\n",
    "\n",
    "#node for the graph\n",
    "def assess_emotional_context(state: ChildState):\n",
    "  emotion_context_prompt = \"\"\"You are a therapist of neurodivergent children. Neurodivergent kid is talking with you. Assess the probability [emotion_p], from 0 to 1, \n",
    "  that content of previous messages can involve any child's emotions. Remember that you should assess only HumanMessages, the ones written by a child\"\"\"\n",
    "  \n",
    "  llm_with_structured_output = llm.with_structured_output(EmotionFormatter)\n",
    "  messages = add_messages(state.messages, HumanMessage(content=emotion_context_prompt))\n",
    "\n",
    "  probability = llm_with_structured_output.invoke(messages)\n",
    "\n",
    "  if probability.emotion_p >= 0.75:\n",
    "    return {'isEmotionalContext': True}\n",
    "  else:\n",
    "    return {'isEmotionalContext': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d347993",
   "metadata": {},
   "source": [
    "### Analyzing mood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc2332",
   "metadata": {},
   "source": [
    "The analysis of mood of a child is very important from the perspective of how the next messages should be expressed by LLM model. If the kid is sad the LLM model should cheer them a bit. On the other hand, if the child is happy, then LLM model should praise for such a behaviour and continue the conversation in the way which supports that emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a89e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a formatter to store probability of emotional context occurence within LLM message in a given format (float)\n",
    "class SentimentFormatter(BaseModel):\n",
    "  sentiment: MoodEnum = Field(description=\"\"\"One of the moods from ['happy', 'sad', 'neutral', 'nervous', 'irritated', 'curious']\"\"\")\n",
    "\n",
    "#create a string from enum of moods given\n",
    "accessible_moods = ', '.join([e.value for e in MoodEnum])\n",
    "\n",
    "#node for the graph\n",
    "def analyze_mood(state: ChildState):\n",
    "  emotion_context_prompt = f\"\"\"You are a therapist of neurodivergent children. Assess the sentiment of previous messages (mood of a child) in one \n",
    "  of those emotions: {accessible_moods}. Remember that you should assess only HumanMessages, the ones written by a child. Additionally, if you think \n",
    "  that more than adjective complies with the criteria, then pick the one which describe better the newest messages\"\"\"\n",
    "  \n",
    "  llm_with_structured_output = llm.with_structured_output(SentimentFormatter)\n",
    "  messages = add_messages(state.messages, HumanMessage(content=emotion_context_prompt))\n",
    "\n",
    "  sentiment = llm_with_structured_output.invoke(messages)\n",
    "\n",
    "  if sentiment.sentiment is not None:\n",
    "    return {'mood': sentiment.sentiment.value}\n",
    "  else:\n",
    "    return {'mood': state.mood}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ac90d",
   "metadata": {},
   "source": [
    "### Generating the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a619f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.messages import format_messages_for_prompt\n",
    "\n",
    "#Generate the LLM model response based on current state\n",
    "def generate_response(state: ChildState):\n",
    "    \n",
    "    #Get current values from the state\n",
    "    child_current_mood = state.mood\n",
    "    social_context_present = state.isSocialContext\n",
    "    emotional_context_present = state.isEmotionalContext\n",
    "    child_name = state.name\n",
    "    child_diagnosis = state.diagnosis\n",
    "    child_age = state.age\n",
    "    language = state.language\n",
    "\n",
    "    #Format recent messages for context\n",
    "    formatted_history = format_messages_for_prompt(state.messages)\n",
    "\n",
    "    #Instruction for a response generation\n",
    "    response_generator_prompt = f\"\"\"\n",
    "        As a therapist create a response to a message of a neurodivergent child.\n",
    "\n",
    "        CONTEXT FOR YOUR RESPONSE:\n",
    "        - Child's current detected mood: {child_current_mood}\n",
    "        - If social interaction context was detected in recent chat: {social_context_present}\n",
    "        - If emotional context was detected in recent chat: {emotional_context_present}\n",
    "\n",
    "        RESPONSE RULES:\n",
    "        1. If mood is 'sad', 'nervous', or 'irritated': Generate a calming, validating, supportive message.\n",
    "        2. If mood is 'happy' or 'curious': Generate a praising, encouraging, engaging message. \n",
    "        3. If mood is 'neutral', generate message which will make them happy.\n",
    "        3. If Social Context Present is False (Current state: {social_context_present}): Make the response have a question \n",
    "        which would cause a child to share experienced social scenario but if there is a factual question/statement in place also respond clearly. \n",
    "        The question should be connected with a factual question/statement and very precise (about one concrete social scenario). \n",
    "        4. If Emotional Context Present is False (Current state: {emotional_context_present}): Make the response have a question or statement \n",
    "        which would cause a child to share experienced emotions but if there is a factual question/statement in place also respond clearly.\n",
    "        The question should be connected with a factual question/statement and very precise (about one concrete emotion). \n",
    "        5. If both contexts are False, you can combine the questions or choose one.\n",
    "        6. Remember that if question is about something specific (eg. historical event) then you should answer it as well\n",
    "        7. Address the child by name ({child_name}) occasionally.\n",
    "        8. Respond ONLY in language: {language}.\n",
    "\n",
    "        RECENT CONVERSATION HISTORY:\n",
    "        {formatted_history}\n",
    "\n",
    "        Based on the rules and context above, generate your response to the child's last message.\n",
    "        Generate ONLY the response text.\n",
    "    \"\"\"\n",
    "\n",
    "    #Construct the prompt \n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=childChatBotSystemMessage(child_diagnosis, child_age, child_current_mood, language)),\n",
    "        HumanMessage(content=response_generator_prompt)\n",
    "    ])\n",
    "\n",
    "    #Invoke the LLM with the constructed prompt\n",
    "    chain = prompt_template | llm\n",
    "    response_content = chain.invoke({}).content # Pass empty dict as input because template handles entire necessary context \n",
    "\n",
    "    # Return the message to be added to the state\n",
    "    # LangGraph's `add_messages` handles appending this\n",
    "    return {\"messages\": [AIMessage(content=response_content)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547591f0",
   "metadata": {},
   "source": [
    "### Formulating a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493dfc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(ChildState)\n",
    "workflow.add_node(\"assess_social_cotext\", assess_social_context)\n",
    "workflow.add_node(\"assess_emotional_cotext\", assess_emotional_context)\n",
    "workflow.add_node(\"analyze_mood\", analyze_mood)\n",
    "workflow.add_node(\"generate_response\", generate_response)\n",
    "\n",
    "workflow.add_edge(START, \"assess_social_cotext\")\n",
    "workflow.add_edge(\"assess_social_cotext\", \"assess_emotional_cotext\")\n",
    "workflow.add_edge(\"assess_emotional_cotext\", \"analyze_mood\")\n",
    "workflow.add_edge(\"analyze_mood\", \"generate_response\")\n",
    "workflow.add_edge(\"generate_response\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleChild = {\n",
    "  'messages': [HumanMessage(content='Kim był Napoleon Bonaparte?')],\n",
    "  'name': 'Adrian',\n",
    "  'age': 12,\n",
    "  'diagnosis': {'adhd': False, 'spectrum': True},\n",
    "  'language': 'pl'\n",
    "}\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "graph.invoke(exampleChild, config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
